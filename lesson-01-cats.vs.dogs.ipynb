{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mylib.data_loaders as data_loaders\n",
    "import mylib.data_transformers as data_transformers\n",
    "import mylib.models_repo as models_repo\n",
    "import mylib.optimizer_repo as optimizer_repo\n",
    "import mylib.scheduler_repo as scheduler_repo\n",
    "import mylib.trainer as trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets.folder import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/home/as/datasets/fastai.dogscats\"\n",
    "num_classes = 2       # Cats & Dogs\n",
    "img_size  = 224       # H and W are expected to be atleast 224 for PyTorch model zoo models\n",
    "scale_img_size = 300  # During data augmentation, we first scale the image to this value, \n",
    "                      # then we take a Random Crop of size (img_size x img_size) from within that image\n",
    "batch_size = 256      # Set as per your GPU RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm = data_transformers.pytorch_zoo_normaliser\n",
    "trans = data_transformers.get_transformer(img_size, scale_img_size, norm, False)\n",
    "trans_aug = data_transformers.get_transformer(img_size, scale_img_size, norm, True)\n",
    "trans_valid = data_transformers.get_test_valid_transformer(img_size, scale_img_size, norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the datasets with the given transformers. Note that ImageFolder() is a utility class in torchvision which can read images which are segregated into class folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vanilla dataset\n",
    "train_images = ImageFolder(f'{data_path}/train', transform=trans)\n",
    "\n",
    "# Augmented dataset\n",
    "train_images_aug = ImageFolder(f'{data_path}/train', transform=trans_aug)\n",
    "\n",
    "# For valid and test datasets\n",
    "valid_images = ImageFolder(f'{data_path}/valid', transform=trans_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of train instances', len(train_images))\n",
    "print('Number of valid instances', len(valid_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classes', train_images.classes)\n",
    "print('Class index', train_images.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the loaders. We will iterate these during training. They will give us our batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader     = data_loaders.get_data_loader(train_images, batch_size)\n",
    "train_loader_aug = data_loaders.get_data_loader(train_images_aug, batch_size)\n",
    "valid_loader     = data_loaders.get_data_loader(valid_images, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try with a vanilla pretrained ResNet, with no augmentation\n",
    "\n",
    "We just replace the last FC layer to account for the num_classes, that's all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Get the model\n",
    "    model = models_repo.model_resnet_vanilla(num_classes)\n",
    "    # Get the optimizer and loss function\n",
    "    criteria, optimizer = optimizer_repo.sgd(model, 0.01, model.fc.parameters(), momentum=0.9, weight_decay=1e-4)\n",
    "    # Get the scheduler\n",
    "    scheduler = scheduler_repo.step_lr(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    print('Layers in the model')\n",
    "    for p in model.children():\n",
    "        print(type(p))\n",
    "    print('Training starts')\n",
    "\n",
    "    # Train!\n",
    "    best_model = trainer.train(model, criteria, optimizer, scheduler, train_loader, valid_loader, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try with a vanilla pretrained ResNet, with no data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Get the model\n",
    "    model = models_repo.model_resnet_vanilla(num_classes)\n",
    "    # Get the optimizer and loss function\n",
    "    criteria, optimizer = optimizer_repo.sgd(model, 0.01, model.fc.parameters(), momentum=0.9, weight_decay=1e-4)\n",
    "    # Get the scheduler\n",
    "    scheduler = scheduler_repo.step_lr(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    print('Layers in the model')\n",
    "    for p in model.children():\n",
    "        print(type(p))\n",
    "    print('Training starts')\n",
    "\n",
    "    # Train!\n",
    "    best_model = trainer.train(model, criteria, optimizer, scheduler, train_loader_aug, valid_loader, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try with a pretrained ResNet with extra FC layers, with no data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, params_to_optimize = models_repo.resnet34_extra_layers(num_classes, top_layers_to_freeze=6, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_to_optimize = models_repo.resnet34_extra_layers(num_classes, top_layers_to_freeze=6,)\n",
    "criteria, optimizer = optimizer_repo.sgd(model, 0.01, params_to_optimize=params_to_optimize)\n",
    "scheduler = scheduler_repo.step_lr(optimizer)\n",
    "\n",
    "best_model = trainer.train(model, criteria, optimizer, scheduler, train_loader_aug, valid_loader, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
