{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mylib.data_loaders as data_loaders\n",
    "import mylib.data_transformers as data_transformers\n",
    "import mylib.models_repo as models_repo\n",
    "import mylib.optimizer_repo as optimizer_repo\n",
    "import mylib.scheduler_repo as scheduler_repo\n",
    "import mylib.trainer as trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets.folder import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/home/as/datasets/fastai.dogscats\"\n",
    "num_classes = 2       # Cats & Dogs\n",
    "img_size  = 224       # H and W are expected to be atleast 224 for PyTorch model zoo models\n",
    "scale_img_size = 300  # During data augmentation, we first scale the image to this value, \n",
    "                      # then we take a Random Crop of size (img_size x img_size) from within that image\n",
    "batch_size = 256      # Set as per your GPU RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm = data_transformers.pytorch_zoo_normaliser\n",
    "trans = data_transformers.get_transformer(img_size, scale_img_size, norm, False)\n",
    "trans_aug = data_transformers.get_transformer(img_size, scale_img_size, norm, True)\n",
    "trans_valid = data_transformers.get_test_valid_transformer(img_size, scale_img_size, norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the datasets with the given transformers. Note that ImageFolder() is a utility class in torchvision which can read images which are segregated into class folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vanilla dataset\n",
    "train_images = ImageFolder(f'{data_path}/train', transform=trans)\n",
    "\n",
    "# Augmented dataset\n",
    "train_images_aug = ImageFolder(f'{data_path}/train', transform=trans_aug)\n",
    "\n",
    "# For valid and test datasets\n",
    "valid_images = ImageFolder(f'{data_path}/valid', transform=trans_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train instances 23000\n",
      "Number of valid instances 2000\n"
     ]
    }
   ],
   "source": [
    "print('Number of train instances', len(train_images))\n",
    "print('Number of valid instances', len(valid_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes ['cats', 'dogs']\n",
      "Class index {'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "print('Classes', train_images.classes)\n",
    "print('Class index', train_images.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the loaders. We will iterate these during training. They will give us our batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader     = data_loaders.get_data_loader(train_images, batch_size)\n",
    "train_loader_aug = data_loaders.get_data_loader(train_images_aug, batch_size)\n",
    "valid_loader     = data_loaders.get_data_loader(valid_images, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try with a vanilla pretrained ResNet, with no augmentation\n",
    "\n",
    "We just replace the last FC layer to account for the num_classes, that's all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Get the model\n",
    "    model = models_repo.model_resnet_vanilla(num_classes)\n",
    "    # Get the optimizer and loss function\n",
    "    criteria, optimizer = optimizer_repo.sgd(model, 0.01, model.fc.parameters(), momentum=0.9, weight_decay=1e-4)\n",
    "    # Get the scheduler\n",
    "    scheduler = scheduler_repo.step_lr(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    print('Layers in the model')\n",
    "    for p in model.children():\n",
    "        print(type(p))\n",
    "    print('Training starts')\n",
    "\n",
    "    # Train!\n",
    "    best_model = trainer.train(model, criteria, optimizer, scheduler, train_loader, valid_loader, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try with a vanilla pretrained ResNet, with no data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Get the model\n",
    "    model = models_repo.model_resnet_vanilla(num_classes)\n",
    "    # Get the optimizer and loss function\n",
    "    criteria, optimizer = optimizer_repo.sgd(model, 0.01, model.fc.parameters(), momentum=0.9, weight_decay=1e-4)\n",
    "    # Get the scheduler\n",
    "    scheduler = scheduler_repo.step_lr(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    print('Layers in the model')\n",
    "    for p in model.children():\n",
    "        print(type(p))\n",
    "    print('Training starts')\n",
    "\n",
    "    # Train!\n",
    "    best_model = trainer.train(model, criteria, optimizer, scheduler, train_loader_aug, valid_loader, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.conv.Conv2d'> 1 0\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'> 2 0\n",
      "<class 'torch.nn.modules.activation.ReLU'> 0 0\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'> 0 0\n",
      "<class 'torch.nn.modules.container.Sequential'> 18 0\n",
      "<class 'torch.nn.modules.container.Sequential'> 27 0\n",
      "<class 'torch.nn.modules.container.Sequential'> 39 39\n",
      "<class 'torch.nn.modules.container.Sequential'> 21 21\n",
      "<class 'mylib.models_repo.AdaptiveConcatPool2d'> 0 0\n",
      "<class 'mylib.models_repo.Flatten'> 0 0\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm1d'> 2 2\n",
      "<class 'torch.nn.modules.linear.Linear'> 2 2\n",
      "<class 'torch.nn.modules.dropout.Dropout'> 0 0\n",
      "<class 'torch.nn.modules.activation.ReLU'> 0 0\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm1d'> 2 2\n",
      "<class 'torch.nn.modules.dropout.Dropout'> 0 0\n",
      "<class 'torch.nn.modules.linear.Linear'> 2 2\n",
      "<class 'torch.nn.modules.activation.LogSoftmax'> 0 0\n"
     ]
    }
   ],
   "source": [
    "model, params_to_optimize = models_repo.resnet34_extra_layers(num_classes, top_layers_to_freeze=6, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54eb4ffd4a4b499397a3ede788ccf18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90it [00:44,  2.03it/s]\n",
      "8it [00:03,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss  : 0.0004949418514481057 , Acc: 0.9455652173913044\n",
      "Validation Loss: 0.0001471586711704731 , Acc: 0.9855\n",
      "############################### Better model found\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "90it [00:44,  2.02it/s]\n",
      "8it [00:03,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss  : 0.0001759736776837836 , Acc: 0.9830434782608696\n",
      "Validation Loss: 0.00012492886278778315 , Acc: 0.989\n",
      "############################### Better model found\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "90it [00:44,  2.02it/s]\n",
      "8it [00:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss  : 0.0001429175592796958 , Acc: 0.9861739130434782\n",
      "Validation Loss: 0.0001228288346901536 , Acc: 0.987\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "90it [00:44,  2.00it/s]\n",
      "8it [00:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss  : 0.00012823270982050377 , Acc: 0.9880434782608696\n",
      "Validation Loss: 0.0001183404135517776 , Acc: 0.99\n",
      "############################### Better model found\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "90it [00:45,  1.99it/s]\n",
      "8it [00:03,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss  : 0.00010639017542986118 , Acc: 0.9893478260869565\n",
      "Validation Loss: 0.000108808150049299 , Acc: 0.99\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "90it [00:45,  1.98it/s]\n",
      "8it [00:03,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss  : 8.904299650179303e-05 , Acc: 0.9918260869565217\n",
      "Validation Loss: 8.126656338572503e-05 , Acc: 0.991\n",
      "############################### Better model found\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "90it [00:45,  1.98it/s]\n",
      "8it [00:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss  : 8.315881250588143e-05 , Acc: 0.9919565217391304\n",
      "Validation Loss: 0.00010625039716251195 , Acc: 0.988\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "90it [00:45,  1.98it/s]\n",
      "8it [00:03,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss  : 9.118514948362566e-05 , Acc: 0.9909130434782609\n",
      "Validation Loss: 0.00010382538381963969 , Acc: 0.9905\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "90it [00:45,  1.98it/s]\n",
      "8it [00:03,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss  : 7.924229720526415e-05 , Acc: 0.992304347826087\n",
      "Validation Loss: 0.00011187818879261613 , Acc: 0.9905\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "90it [00:46,  1.95it/s]\n",
      "8it [00:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss  : 8.160859210740612e-05 , Acc: 0.9925652173913043\n",
      "Validation Loss: 0.00010679071117192507 , Acc: 0.9875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, params_to_optimize = models_repo.resnet34_extra_layers(num_classes, top_layers_to_freeze=6)\n",
    "criteria, optimizer = optimizer_repo.sgd(model, 0.01, params_to_optimize=params_to_optimize)\n",
    "scheduler = scheduler_repo.step_lr(optimizer)\n",
    "\n",
    "best_model = trainer.train(model, criteria, optimizer, scheduler, train_loader_aug, valid_loader, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
