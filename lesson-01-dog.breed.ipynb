{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lib.data_loaders as data_loaders\n",
    "import lib.data_transformers as data_transformers\n",
    "import lib.datasets as ds\n",
    "import lib.models_repo as models_repo\n",
    "import lib.optimizer_repo as optimizer_repo\n",
    "import lib.scheduler_repo as scheduler_repo\n",
    "import lib.trainer as trainer\n",
    "import lib.model_saver as model_saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets.folder import ImageFolder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/home/as/datasets/kaggle.dog.breed/train\"\n",
    "csv_file = \"/home/as/datasets/kaggle.dog.breed/labels.csv\"\n",
    "sample_submission_file = '/home/as/datasets/kaggle.dog.breed/sample_submission.csv'\n",
    "\n",
    "num_classes = 120\n",
    "img_size  = 340\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm = data_transformers.resnet_normaliser\n",
    "trans = data_transformers.get_transformer(img_size, norm, False)\n",
    "trans_aug = data_transformers.get_transformer(img_size, norm, True)\n",
    "trans_valid = data_transformers.get_test_valid_transformer(img_size, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.random.seed(42)\n",
    "labels = pd.read_csv(csv_file)\n",
    "mask = np.random.rand(len(labels)) < 0.75\n",
    "labels_train = labels[mask].values\n",
    "labels_valid = labels[~mask].values\n",
    "sub = pd.read_csv(sample_submission_file,)\n",
    "breeds = list(sub)[1:]\n",
    "\n",
    "train_images = ds.DatasetFromCSV(labels_train, breeds, data_path, 'jpg', transform=trans)\n",
    "train_images_aug = ds.DatasetFromCSV(labels_train, breeds, data_path, 'jpg', transform=trans_aug)\n",
    "valid_images = ds.DatasetFromCSV(labels_valid, breeds, data_path, 'jpg', transform=trans_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of train instances', len(train_images))\n",
    "print('Number of valid instances', len(valid_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classes', train_images.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = data_loaders.get_data_loader(train_images, batch_size)\n",
    "train_loader_aug = data_loaders.get_data_loader(train_images_aug, batch_size)\n",
    "valid_loader = data_loaders.get_data_loader(valid_images, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = models_repo.resnet_vanilla(num_classes)\n",
    "    criteria, optimizer = optimizer_repo.sgd(model, 0.01)\n",
    "    scheduler = scheduler_repo.step_lr(optimizer)\n",
    "\n",
    "    best_model = trainer.experiment(model, criteria, optimizer, scheduler, train_loader, valid_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    model = models_repo.resnet_vanilla(num_classes)\n",
    "    criteria, optimizer = optimizer_repo.sgd(model, 0.01)\n",
    "    scheduler = scheduler_repo.step_lr(optimizer)\n",
    "\n",
    "    best_model = trainer.experiment(model, criteria, optimizer, scheduler, train_loader_aug, valid_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_to_optimize = models_repo.resnet_extra_layers(num_classes, top_layers_to_freeze=7, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_to_optimize = models_repo.resnet_extra_layers(num_classes, top_layers_to_freeze=7)\n",
    "criteria, optimizer = optimizer_repo.sgd(model, 0.01, params_to_optimize=params_to_optimize)\n",
    "scheduler = scheduler_repo.step_lr(optimizer, 20, 0.01)\n",
    "\n",
    "ret = trainer.experiment(model, criteria, optimizer, scheduler, train_loader_aug, valid_loader, 100)\n",
    "model, train_loss_trend, val_loss_trend, best_epoch, best_accuracy, best_loss = ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_trend)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_loss_trend)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = model_saver.save_checkpoint(best_epoch, 'resnet34', best_model, best_accuracy, \n",
    "                                best_loss, optimizer, 'dog.breed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred(img_path):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = trans_valid(img)\n",
    "    img = autograd.Variable(torch.unsqueeze(img, 0).cuda())\n",
    "    bm = best_model.cuda()\n",
    "    output = bm(img)\n",
    "    arr = output.data.cpu().numpy()[0]\n",
    "    arr = np.exp(arr) / np.sum(np.exp(arr))\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('/tmp/submission.csv', 'w')\n",
    "\n",
    "\n",
    "for file in os.listdir('/home/as/datasets/kaggle.dog.breed/test'):\n",
    "    p = os.path.join('/home/as/datasets/kaggle.dog.breed/test', file)\n",
    "    arr = pred(p)\n",
    "    s = ''\n",
    "    for a in arr:\n",
    "        s += ',' + str(a)\n",
    "    f.write(file.replace('.jpg', '') + s + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argmax(arr)\n",
    "np.argmax(output.data.cpu().numpy()[0])\n",
    "breeds[41]\n",
    "output.data.cpu().numpy()[0][59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = []\n",
    "w = []\n",
    "\n",
    "for file in os.listdir('/home/as/datasets/kaggle.dog.breed/train'):\n",
    "    p = os.path.join('/home/as/datasets/kaggle.dog.breed/train', file)\n",
    "    img = Image.open(p).convert('RGB')\n",
    "    h.append(img.size[0])\n",
    "    w.append(img.size[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(340 - np.min(h))\n",
    "print(340 - np.min(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.randint(0, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
